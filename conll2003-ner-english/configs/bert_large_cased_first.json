{
    "description": "BERT large cased with First Subword Pooling and Scalar Mix",
    "embeddings": ["bert-large-cased"],
    "layers": [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],
    "batch_size": 16,
    "hidden_size": 256,
    "max_epochs": 500,
    "embeddings_storage_mode": "gpu",
    "pooling_operation": "first",
    "use_crf": true,
    "use_scalar_mix": true,
    "train_with_dev": false
}